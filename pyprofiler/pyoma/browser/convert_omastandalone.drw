if not assigned(root_dir) then
    root_dir := getenv('DARWIN_BROWSERDATA_PATH');
fi:
libdir := root_dir.'/lib/';
ReadProgram(root_dir.'/lib/darwinit');
ReadProgram(root_dir.'/parameters.drw');
G := TimedCallSystem('find -L '.root_dir.'/DB -name "*.fa" -print')[2];
G := sort(SearchDelim('\n',G));
_next_new_taxid := -100;
genomes := []: DBs := table(): GS := table(): TaxonIDs := table(): isContig := []: DBhashes := []:
for g in G do
    off := SearchAllString('/', g);
    gname := g[off[-1]+1..-1];
    isContig := append(isContig, evalb(SearchString('contig', gname) > -1));
    off := SearchString('.',gname);
    gname := gname[1..off];
    genomes := append(genomes, gname):
    DB := ReadDb(root_dir.'/Cache/DB/'.gname.'.db');
    GS[gname] := GenomeSummary(DB):
    DBs[gname] := DB;
    tax := SearchTag('TAXONID', DB['string']);
    if tax='' then
        TaxonIDs[gname] := _next_new_taxid; _next_new_taxid := _next_new_taxid - 1;
    else
        TaxonIDs[gname] := tax;
    fi:
    DBhashes := append(DBhashes, sha2(DB['string'])[1..16]):
od:
NS := length(genomes);
Goff := CreateArray(1..NS+1):
for i to NS do Goff[i+1] := Goff[i]+GS[genomes[i],TotEntries] od:
Lengths := [seq(GS[g, EntryLengths], g=genomes)]:
ns := [seq(GS[g, TotEntries], g=genomes)]:
SubGenome := table(0);



# code from PhylogeneticTree (LINEAGE) augmented to store the internal
# node names.
SpeciesTreeR := proc( l, lev, parent )
    global _parents;
#    print('',l);
#    lprint(lev,parent, length(l), min( seq(length(r[1]), r=l )));
    if length(l)=0 then error('null tree')
    elif length(l)=1 then
        tax := parse(GS[l[1,2],TAXONID]);
        _parents := append(_parents, [tax, parent, GS[l[1,2],'SCINAME']]);
        #Leaf(l[1,2],length(l[1,1])+1)
    elif lev > min( seq(length(r[1]), r=l )) then
        tax := parse(GS[l[1,2], TAXONID]);
        if tax<>parent then
            _parents := append(_parents,
                [tax, parent, TaxonomyEntry(tax)['SciName']]);
        else
            warning('tax '.string(tax).' is already recorded.');
        fi:
        procname(l[2..-1], lev, parent);
        #Tree( Leaf(l[1,2],length(l[1,1])+1), lev, procname( l[2..-1], lev ))
    else
        card := { seq( r[1,lev], r=l ) };
        tax := getTaxid(l[1,1,lev]);
        _parents := append(_parents, [tax, parent, l[1,1,lev]]);
        if length(card)=1 then
            return( procname(l, lev+1, tax) );
        fi;
        for hi from 2 while l[1,1,lev] = l[hi,1,lev] do od;
        procname( l[1..hi-1], lev+1, tax );
        procname( l[hi..-1], lev, parent );
    fi:
end:

TreeToParentTable := proc(tree, parent; (h0=0):numeric)
    global _parents, _next_new_taxid;
    if length(tree)=0 then error('null tree');
    elif type(tree, Leaf) then
        sciname := GS[tree['Label'], SCINAME];
        if sciname = '' then sciname := tree['Label'] fi:
        _parents := append(_parents, [TaxonIDs[tree['Label']], parent, sciname]);
        return({tree['Label']});
    else
        branchlength := |tree['Height'] - h0|;
        next_parent := parent;
        if branchlength > 1e-4 then
            next_parent := _next_new_taxid;
            _next_new_taxid := _next_new_taxid - 1;
        fi:
        tL := procname(tree['Left'], next_parent, tree['Height']);
        tR := procname(tree['Right'], next_parent, tree['Height']);
        covered := union(tL, tR);
        lev := ConcatStrings([op(covered)], '/');
        if next_parent<>parent then
            _parents := append(_parents, [next_parent, parent, lev]);
        fi:
        return(covered);
    fi:
end:


getTaxid := proc(lin)
    global _next_new_taxid;
    tax := traperror(TaxonomyEntry(lin)['id']);
    if tax=lasterror then
        tax := _next_new_taxid;
        _next_new_taxid := _next_new_taxid-1;
    fi:
    return(tax);
end:

GetGenomeFileNames := proc()
    StoreResults(json([seq(GS[g,'FileName'], g=genomes)]));
end:

GetGenomeData := proc()
    global _parents;
    gs := [];
    for gNr to NS do
        g := genomes[gNr];
        sciname := GS[g,SCINAME];
        if sciname='' then sciname := g fi:
        last_modified := GS[g, 'DATE'];
        if last_modified = '' then
            fs := FileStat(GS[g,FileName]);
            last_modified := fs['st_mtime'];
        fi:
        gs := append(gs, [TaxonIDs[g], GS[g, '5LETTERNAME'], GS[g,TotEntries],
            GS[g,TotAA], Goff[gNr], sciname ,GS[g,COMMONNAME], GS[g, SYNNAME],
            GS[g,DBRELEASE], GS[g,URL], GS[g,SOURCE], last_modified,
            SubGenome[g]<>0]);
    od:

    tab := table():
    tab['GS'] := gs:
    _parents := []:
    if lower(SpeciesTree)='lineage' then
        linData := sort([seq([GS[g,Lineage], g], g=genomes)]):
        SpeciesTreeR(linData, 1, 0);
    else
        stree := SpeciesTree;
        if lowercase(SpeciesTree)='estimate' then
            stree := ReadRawFile(root_dir.'/'.OutputFolder.'/EstimatedSpeciesTree.nwk');
        fi:
        TreeToParentTable(ParseNewickTree(stree), 0):
        _parents := append(_parents, [0,0,'LUCA']);
    fi:
    tab['Tax'] := _parents:
    StoreResults(json(tab));
end:

WriteRelationsToTSV := proc(gNr1, gNr2, matches, cache_dir)
    buf_homolog := buf_vp := buf_sp := [];
    for x1 to length(matches) do if matches[x1]<>[] then
        for m in decompress(matches[x1]) do
            fmt := sprintf('%d\t%d\t%.3f\t%%s\t%.7g\t%.10g',
                    Goff[gNr1]+ x1, Goff[gNr2]+ m['Entry'], m['Score100']/100,
                    m['SumLengths']/(Lengths[gNr1,x1] + Lengths[gNr2,m['Entry']]),
                    m['PamDist10000']/10000);
            buf_homolog := append(buf_homolog, sprintf(fmt, 'homolog'));
            if gNr1<>gNr2 and member(m['Entry'], StablePairs[gNr1, gNr2, x1]) then
                buf_sp := append(buf_sp, sprintf(fmt, 'n/a'));
            fi:
            if gNr1<>gNr2 and member(m['Entry'], VPairs[gNr1, gNr2, x1]) then
                nr2 := If(length(VPairs[gNr1, gNr2, x1])>1,'n','1'):
                nr1 := If(length(VPairs[gNr2, gNr1, m['Entry']])>1, 'm', '1');
                buf_vp := append(buf_vp, sprintf(fmt, nr1.':'.nr2));
            fi:
        od:
    fi od:
    if length(buf_homolog)>0 then
        OpenAppending(cache_dir.'/homologs/'.GS[genomes[gNr1],'5LETTERNAME'].'.txt');
        prints(ConcatStrings(buf_homolog, '\n'));
        OpenAppending(previous);
    fi:
    if length(buf_vp)>0 then
        OpenAppending(cache_dir.'/vps/'.GS[genomes[gNr1],'5LETTERNAME'].'.txt');
        prints(ConcatStrings(buf_vp, '\n'));
        OpenAppending(previous);
    fi:
end:

TransformDataToCache := proc(cache_dir)
    global VPairs, Paralogs, StablePairs, Ort, VPs, rev;

    milestone_file := root_dir.'/Cache/ortholog_milestone.drw.gz':
    milestone_sha2 := sha2(ReadRawFile(milestone_file)):
    if FileExists(cache_dir.'/transform_done') and 
       trim(ReadRawFile(cache_dir.'/transform_done'))=milestone_sha2 then 
        StoreResults(json('success')):
        return();
    fi:
    
    ReadProgram(root_dir.'/Cache/ortholog_milestone.drw.gz');
    Prot2Grp := CreateArray(1..Goff[NS+1]):
    for og to length(Ort) do for gNr to NS do if Ort[og,gNr]<>0 then
        Prot2Grp[Goff[gNr]+Ort[og,gNr]] := og;
    fi od od:
    CallSystem('mkdir -p '.cache_dir.'/{vps,prots,homologs}');
    for g in genomes do
        StoreProteinsForGenome(g, Prot2Grp, cache_dir.'/prots/'.GS[g,'5LETTERNAME'].'.json');
    od:

    InitAllAll();
    for gNr1 to NS do
        for gNr2 from gNr1 to NS do
            matches := LoadAllAll(gNr1, gNr2);
            WriteRelationsToTSV(gNr1, gNr2, matches[1], cache_dir);
            if gNr1<>gNr2 then
                WriteRelationsToTSV(gNr2, gNr1, matches[2], cache_dir);
            fi:
        od:
        CallSystem('gzip -6 '.cache_dir.'/{vps,homologs}/'.GS[genomes[gNr1],'5LETTERNAME'].'.txt');
    od:
    OpenWriting(cache_dir.'/transform_done'):
    prints(milestone_sha2);
    OpenWriting(previous):

    StoreResults(json('success'));
    
end:

NumberOfAlignments := proc(name1:string,name2:string)
    if name1=name2 then
        nrAlignments := GS[name1,TotEntries]*(GS[name1,TotEntries]-1)/2;
    else
        nrAlignments := GS[name1,TotEntries]*GS[name2,TotEntries];
    fi:
    return(nrAlignments);
end:

NumberOfChunks := proc(name1, name2)
    return(ceil(NumberOfAlignments(name1, name2)/AlignBatchSize));
end:

InitAllAll := proc()
    global t1,t2,t3,t4,t5,t6,t7, Exclude1, Exclude2;
    t1 := Counter('RefinedMatches structures read'):
    t2 := Counter('Matches read'):
    t3 := Counter('files read'):
    t4 := Counter('Matches of genomes against themselves'):
    t5 := Counter('Matches above parameters');
    t6 := Counter('empty all-all'):
    t7 := Counter('Number of matches discarded below MinSeqLen');
    Exclude1 := Exclude2 := {}:
end:

LoadAllAll := proc(i, j)
    global BestMatch1, BestMatch2, t1,t2,t3,t4,t5,t6,t7, g1, g2, db1, db2;

    BestMatch1 := BestMatch2 := CreateArray(1..ns[i],[]);
    if j>i then BestMatch2 := CreateArray(1..ns[j],[]) fi;
    if ns[i] < ns[j] or ns[i]=ns[j] and genomes[i] < genomes[j] then
        g1 := i;  g2 := j; swap := false; else g2 := i;  g1 := j; swap := true; fi;
    if swap then t := BestMatch1; BestMatch1 := BestMatch2: BestMatch2 := t fi:
    t3+1;
    db1 := DBs[genomes[g1]]; db2 := DBs[genomes[g2]]:
    # if there exist a 1-chunk archive, process it with higher priority
    fn1chunk := sprintf('%s/Cache/AllAll/%s/%s.gz', root_dir, genomes[g1],genomes[g2]);
    if FileExists(fn1chunk) then
        fnSepHash := sprintf('%s/Cache/AllAll/%s/%s.sha2.gz', root_dir, genomes[g1], genomes[g2]);
        if FileExists(fnSepHash) then ReadProgram(fnSepHash) fi:
        ReadProgram(fn1chunk);
    else
        nrChunks := NumberOfChunks(genomes[g1],genomes[g2]);
        for part to nrChunks do
            fn := sprintf('%s/Cache/AllAll/%s/%s/part_%d-%d', root_dir, genomes[g1],genomes[g2],
                part, nrChunks);
            stat := ReadProgram( fn );
            if stat=lasterror then
                warning(stat);
                warning(sprintf('Cannot read file allall file "%s". Please remove it and restart', fn));
                exit(1);
            fi;
        od:
    fi;
    # no Pairs should be cut for being below the Scoretol, as those
    # may serve to break a stable pair
    for mach in [BestMatch1, BestMatch2] do
        for k to length(mach) do
            if mach[k] <> [] then mach[k] := compress(mach[k]) fi od;
    od:
    printf('# Matches loaded. Mem: %.3fGB\n', Set(BytesAlloc)/2^30);
    if swap then t := BestMatch1; BestMatch1 := BestMatch2; BestMatch2 := t fi:
    return( [BestMatch1, BestMatch2] );
end:

GetVPsForGenome := proc(g)
    global DB;
    ReadDb(ddir.'/ServerVPs.db');
    gNr := SearchArray(g,genomes);
    vptab := []:
    for i from Goff[gNr]+1 to Goff[gNr+1] do
        for vp in parse(SearchTag('VP',Entry(i))) do
            vptab := append(vptab, [i, vp, 'n/a'])
        od:
    od:
    StoreResults(json(vptab)):
end:

GetSameSpeciesRelations := proc(g)
    global DB;
    ReadDb(ddir.'/ServerVPs.db');
    gNr := SearchArray(g, genomes);
    ssTab :=  []:
    for i from Goff[gNr]+1 to Goff[gNr+1] do
        e := Entry(i);
        for cp in parse(SearchTag('CP', e)) do
            ssTab := append(ssTab, [i, cp, 'close paralog', -1, -1, -1, -1]);
        od:
        hpTag := SearchTag('HP', e);
        if hpTag<>'' then for hp in parse(hpTag) do
            ssTab := append(ssTab, [i, hp[1], 'homeolog', -1, hp[2], -1, -1, -1]);
        od fi:
    od:
    StoreResults(json(ssTab));
end:

StoreProteinsForGenome := proc(g, grps, fname)
    global DB, Splicings;
    tab:= table():
    gNr := SearchArray(g, genomes);
    DB := DBs[g];
    tab['seqs'] := [seq(Sequence(Entry(i)),i=1..GS[g,TotEntries])]:
    tab['cdna'] := [seq(CreateString(length(z)*3, 'X'), z=tab['seqs'])]:
    tab['off'] := Goff[gNr]:
    tab['ogs'] := grps[Goff[gNr]+1..Goff[gNr+1]];
    tab['chrs'] := [seq(SearchTag('CHR',Entry(i)), i=1..GS[g,TotEntries])];
    tab['locs'] := [seq(SearchTag('LOC',Entry(i)), i=1..GS[g,TotEntries])];
    if SubGenome[g]<>0 then
        tab['subgenome'] := [seq(SubGenome[g,i], i=1..GS[g,TotEntries])]
    else
        tab['subgenome'] := [seq('', GS[g,TotEntries])]
    fi:
    alt := CreateArray(1..GS[g,TotEntries]):

    # TODO: fix splicing variants
    if GS[g, 'SPLICEMAP'] = 'ksfls' then
        hasO := [seq(evalb(SearchTag('VP',Entry(Goff[gNr]+i))<>'[]'),
                     i=1..GS[g,TotEntries])]:
        for i to GS[g,TotEntries] do
            if alt[i]=0 and length(sp[i])>0 then
                vari := [op({op(sp[i]),i})];
                varHasO := [seq(hasO[i],i=vari)];
                main := SearchAllArray(true, varHasO);
                if length(main)=0 then
                    main := vari[1]+Goff[gNr];
                else
                    if length(main)>1 then
                        warning('more than one main variant for '.g.string(vari));
                    fi:
                    main := vari[main[1]]+Goff[gNr];
                fi;
                for k to length(vari) do
                    alt[vari[k]] := main;
                od:
            fi:
        od:
    fi:

    tab['alts'] := alt;
    StoreResults(json(tab), fname):
end:



StoreResults := proc(res, fname)
    if nargs = 1 then
        return(procname(args, outfn))
    fi:
    OpenWriting(fname);
    prints(res);
    OpenWriting(previous);
end:

