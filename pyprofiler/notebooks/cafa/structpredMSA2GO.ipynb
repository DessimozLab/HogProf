{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#recycle RNN2struct for the purpose of GO pred. Use distmat data w aln data from pdb70\n",
    "#use cath mapping for GO terms\n",
    "#2 outputs. train on cath pt sequence and distmat pca\n",
    "\n",
    "import numpy as np\n",
    "from keras.models import *\n",
    "from keras.optimizers import *\n",
    "from keras.layers import *\n",
    "from keras.callbacks import *\n",
    "from keras.models import load_model\n",
    "import datetime\n",
    "import numpy as np\n",
    "from sklearn.base import TransformerMixin\n",
    "from sklearn.preprocessing import StandardScaler,  Normalizer , MinMaxScaler , RobustScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "epsilon = K.epsilon()\n",
    "from io import BytesIO, StringIO\n",
    "from tensorflow.python.lib.io import file_io\n",
    "import argparse\n",
    "import keras\n",
    "global max_epochs\n",
    "\n",
    "flag_show_plots = True # True for Notebooks, False otherwise\n",
    "if flag_show_plots:\n",
    "    import matplotlib.pyplot as plt\n",
    "    from matplotlib.pyplot import figure\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Flatten, Input, Dense , Bidirectional , ConvLSTM2D , concatenate , Reshape , CuDNNGRU , subtract , SpatialDropout2D\n",
    "\n",
    "from keras import backend\n",
    "from keras.callbacks import Callback as Callback\n",
    "from keras.backend import tensorflow_backend as K\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "################################################################################\n",
    "dirlocal = './'\n",
    "dataset = 'full' # 'sample' or 'full'\n",
    " \n",
    "modelfile = 'model-' + str(stamp) + '.h5'\n",
    "\n",
    "max_epochs = 64\n",
    "es_patience = 100\n",
    "\n",
    "if dataset == 'sample':\n",
    "    max_epochs = 8\n",
    "    es_patience = 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class NDSRobust(TransformerMixin):\n",
    "    def __init__(self, **kwargs):\n",
    "        self._scaler = RobustScaler(copy=True, **kwargs)\n",
    "        self._orig_shape = None\n",
    "\n",
    "    def fit(self, X, **kwargs):\n",
    "        X = np.array(X)\n",
    "        # Save the original shape to reshape the flattened X later\n",
    "        # back to its original shape\n",
    "        \n",
    "        if len(X.shape) > 1:\n",
    "            self._orig_shape = X.shape[1:]\n",
    "        X = self._flatten(X)\n",
    "        self._scaler.fit(X, **kwargs)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, **kwargs):\n",
    "        X = np.array(X)\n",
    "        X = self._flatten(X)\n",
    "        X = self._scaler.transform(X, **kwargs)\n",
    "        X = self._reshape(X)\n",
    "        return X\n",
    "    \n",
    "    def inverse_transform(self, X, **kwargs):\n",
    "        X = np.array(X)\n",
    "        X = self._flatten(X)\n",
    "        X = self._scaler.inverse_transform(X, **kwargs)\n",
    "        X = self._reshape(X)\n",
    "        return X\n",
    "    \n",
    "    def _flatten(self, X):\n",
    "        # Reshape X to <= 2 dimensions\n",
    "        if len(X.shape) > 2:\n",
    "            n_dims = np.prod(self._orig_shape)\n",
    "            X = X.reshape(-1, n_dims)\n",
    "        return X\n",
    "\n",
    "    def _reshape(self, X):\n",
    "        # Reshape X back to it's original shape\n",
    "        if len(X.shape) >= 2:\n",
    "            X = X.reshape(-1, *self._orig_shape)\n",
    "        return X\n",
    "\n",
    "\n",
    "class NDSPCA(TransformerMixin):\n",
    "    def __init__(self, **kwargs):\n",
    "        self._scaler = PCA(copy = True, **kwargs)\n",
    "        self._orig_shape = None\n",
    "\n",
    "    def fit(self, X, **kwargs):\n",
    "        X = np.array(X)\n",
    "        # Save the original shape to reshape the flattened X later\n",
    "        # back to its original shape\n",
    "        \n",
    "        if len(X.shape) > 1:\n",
    "            self._orig_shape = X.shape[1:]\n",
    "        X = self._flatten(X)\n",
    "        self._scaler.fit(X, **kwargs)\n",
    "        self.explained_variance_ratio_ = self._scaler.explained_variance_ratio_\n",
    "        self.components_ =self._scaler.components_\n",
    "        \n",
    "        return self\n",
    "\n",
    "    def transform(self, X, **kwargs):\n",
    "        X = np.array(X)\n",
    "        X = self._flatten(X)\n",
    "        X = self._scaler.transform(X, **kwargs)\n",
    "        \n",
    "        return X\n",
    "    \n",
    "    def inverse_transform(self, X, **kwargs):\n",
    "        X = np.array(X)\n",
    "        X = self._flatten(X)\n",
    "        X = self._scaler.inverse_transform(X, **kwargs)\n",
    "        X = self._reshape(X)\n",
    "        return X\n",
    "\n",
    "    def _flatten(self, X):\n",
    "        # Reshape X to <= 2 dimensions\n",
    "        if len(X.shape) > 2:\n",
    "            n_dims = np.prod(self._orig_shape)\n",
    "            X = X.reshape(-1, n_dims)\n",
    "        return X\n",
    "\n",
    "    def _reshape(self, X):\n",
    "        # Reshape X back to it's original shape\n",
    "        if len(X.shape) >= 2:\n",
    "            X = X.reshape(-1, *self._orig_shape)\n",
    "        return X\n",
    "    \n",
    "\n",
    "def fit_y( y , components = 300 , FFT = False ):\n",
    "    if FFT == True:\n",
    "        y = np.stack([ np.fft.rfft2(y[i,:,:]) for i in range(y.shape[0])] )\n",
    "        print(y.shape)\n",
    "        y =  np.hstack( [ np.real(y) , np.imag(y)]  )\n",
    "    print(y.shape)\n",
    "    ndpca = NDSPCA(n_components=components)\n",
    "    ndpca.fit(y)\n",
    "    print('explained variance')\n",
    "    print(np.sum(ndpca.explained_variance_ratio_))\n",
    "    y = ndpca.transform(y)\n",
    "    scaler0 = RobustScaler( )\n",
    "    scaler0.fit(y)\n",
    "    return scaler0, ndpca \n",
    "\n",
    "def transform_y( y, scaler,ndpca , FFT = False ):\n",
    "    if FFT == True:\n",
    "        y = np.stack([ np.fft.rfft2(y[i,:,:]) for i in range(y.shape[0])] )\n",
    "        print(y.shape)\n",
    "        y =  np.hstack( [ np.real(y) , np.imag(y)]  )\n",
    "    y = ndpca.transform(y)\n",
    "    print(y.shape)\n",
    "    y = scaler0.transform(y)\n",
    "    \n",
    "    return y \n",
    "\n",
    "def inverse_transform_y( y , scaler, ndpca , FFT=False):\n",
    "    \n",
    "    y = scaler0.inverse_transform(y)\n",
    "    y = ndpca.inverse_transform(y)\n",
    "\n",
    "    if FFT == True:\n",
    "        split = int(y.shape[1]/2)\n",
    "        y = np.stack([ np.fft.irfft2(y[i,:split,:] + 1j*y[i,split:,:]) for i in range(y.shape[0]) ] )\n",
    "                  \n",
    "    return y\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    0           1\n",
      "0          A0A1Q6BRU5  A0A1Q6BRU5\n",
      "1          A0A0A9U2E6  A0A0A9U2E6\n",
      "2          A0A1Y6B8R2  A0A1Y6B8R2\n",
      "3          A0A1Y6B8R2  A0A2E8I3A4\n",
      "4          A0A094PJX3  A0A094PJX3\n",
      "5          A0A0P6A7Z7  A0A0P6A7Z7\n",
      "6          A0A2E2XLC2  A0A2E2XLC2\n",
      "7          A0A0L9UG40  A0A0L9UG40\n",
      "8          A0A2W6D8L2  A0A2W6D8L2\n",
      "9          A0A1R1PVC7  A0A1R1PVC7\n",
      "10         A0A200R9F7  A0A200R9F7\n",
      "11         A0A1Q5T2G7  A0A1Q5T2G7\n",
      "12         A0A0J6YAJ9  A0A0J6YAJ9\n",
      "13         A0A0J6YAJ9  A0A0J8RQ30\n",
      "14         A0A0J6YAJ9  A0A0J8QT49\n",
      "15         A0A0J6YAJ9      E9D7I5\n",
      "16         A0A0J6YAJ9  A0A0J6FKZ9\n",
      "17         A0A2B2HHJ2  A0A2B2HHJ2\n",
      "18         A0A2B2HHJ2  A0A1X6Q0Z3\n",
      "19         A0A2B2HHJ2      R8HZC0\n",
      "20         A0A2B2HHJ2      R8PED3\n",
      "21         A0A2B2HHJ2  A0A1V9W5F1\n",
      "22         A0A2B2HHJ2  A0A2A7HR05\n",
      "23         A0A2B2HHJ2  A0A2B9B3R7\n",
      "24         A0A2B2HHJ2  A0A150BE34\n",
      "25         A0A2B2HHJ2      K0FM31\n",
      "26         A0A2B2HHJ2  A0A2T0EFU9\n",
      "27         A0A2B2HHJ2  A0A1J9Y0R4\n",
      "28         A0A2B2HHJ2  A0A1D3N8K2\n",
      "29         A0A2B2HHJ2  A0A2C0YGR7\n",
      "...               ...         ...\n",
      "125356040  A0A1F9Q7I8  A0A1F9UXV0\n",
      "125356041  A0A1F9Q7I8  A0A1F9XYF6\n",
      "125356042  A0A1F9Q7I8  A0A1F9VR95\n",
      "125356043  A0A1F9Q7I8  A0A1F9T5K4\n",
      "125356044  A0A1F9Q7I8  A0A1F9TLA8\n",
      "125356045  A0A1F9Q7I8  A0A1J4SQK7\n",
      "125356046  A0A1F9Q7I8  A0A1F9SQG8\n",
      "125356047  A0A1F9Q7I8  A0A1F9SHX4\n",
      "125356048      E4XHC2      E4XHC2\n",
      "125356049  A0A2W6RD06  A0A2W6RD06\n",
      "125356050  A0A2E9R0M1  A0A2E9R0M1\n",
      "125356051  A0A0P5CXH2  A0A0P5CXH2\n",
      "125356052  A0A0P5CXH2  A0A0P5E5N1\n",
      "125356053  A0A0P5CXH2  A0A0P5T1I1\n",
      "125356054  A0A0P5CXH2  A0A0P5UEC3\n",
      "125356055  A0A0P5CXH2  A0A0P5N0Q5\n",
      "125356056  A0A0P5CXH2      E9HMX2\n",
      "125356057  A0A0P5CXH2  A0A0P5CA83\n",
      "125356058  A0A0P5CXH2  A0A0P5N134\n",
      "125356059  A0A0A9J4Y1  A0A0A9J4Y1\n",
      "125356060  A0A0B2W5I3  A0A0B2W5I3\n",
      "125356061  A0A0J7NNV1  A0A0J7NNV1\n",
      "125356062  A0A2E4D3J2  A0A2E4D3J2\n",
      "125356063  A0A2E4D3J2  A0A2V7GJ22\n",
      "125356064  A0A2E4D3J2  A0A2V7G710\n",
      "125356065  A0A2E4D3J2  A0A1Q7PT73\n",
      "125356066  A0A2E4D3J2  A0A2E4KGR1\n",
      "125356067  A0A2E4D3J2  A0A0S8BLK5\n",
      "125356068  A0A2E4D3J2  A0A2E9ZQ81\n",
      "125356069  A0A2W1U1C4  A0A2W1U1C4\n",
      "\n",
      "[125356070 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "### todo, get MSAs, get pdb distmats, get pdb GO\n",
    "import pandas as pd\n",
    "uniclust = '/home/cactuskid13/mntpt/HHBLITsdb/uniclust30_2018_08/uniclust30_2018_08.tsv'\n",
    "dfclust = pd.read_csv( uniclust , comment = '!' , sep = '\\t' , header = None )\n",
    "print(dfclust)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         PDB CHAIN SP_PRIMARY  RES_BEG  RES_END PDB_BEG PDB_END  SP_BEG  \\\n",
      "0       101m     A     P02185        1      154       0     153       1   \n",
      "1       102l     A     P00720        1       40       1      40       1   \n",
      "2       102l     A     P00720       42      165      41    None      41   \n",
      "3       102m     A     P02185        1      154       0     153       1   \n",
      "4       103l     A     P00720        1       40       1    None       1   \n",
      "5       103l     A     P00720       44      167      41    None      41   \n",
      "6       103m     A     P02185        1      154       0     153       1   \n",
      "7       104l     A     P00720        1       44       1      44       1   \n",
      "8       104l     A     P00720       47      166      45    None      45   \n",
      "9       104l     B     P00720        1       44       1      44       1   \n",
      "10      104l     B     P00720       47      166      45    None      45   \n",
      "11      104m     A     P02185        1      153       1     153       2   \n",
      "12      105m     A     P02185        1      153       1     153       2   \n",
      "13      106m     A     P02185        1      154       0     153       1   \n",
      "14      107l     A     P00720        1      164       1    None       1   \n",
      "15      107m     A     P02185        1      154       0     153       1   \n",
      "16      108l     A     P00720        1      164       1    None       1   \n",
      "17      108m     A     P02185        1      154       0     153       1   \n",
      "18      109l     A     P00720        1      164       1    None       1   \n",
      "19      109m     A     P02185        1      154       0     153       1   \n",
      "20      10gs     A     P09211        1      209    None     209       2   \n",
      "21      10gs     B     P09211        1      209    None     209       2   \n",
      "22      10mh     A     P05102        1      327       1     327       1   \n",
      "23      110l     A     P00720        1      164       1    None       1   \n",
      "24      110m     A     P02185        1      154       0     153       1   \n",
      "25      111l     A     P00720        1      164       1    None       1   \n",
      "26      111m     A     P02185        1      154       0     153       1   \n",
      "27      112l     A     P00720        1      164       1    None       1   \n",
      "28      112m     A     P02185        1      154       0     153       1   \n",
      "29      113l     A     P00720        1      164       1    None       1   \n",
      "...      ...   ...        ...      ...      ...     ...     ...     ...   \n",
      "480234  9ins     B     P01315        1       30       1      30      25   \n",
      "480235  9jdw     A     P50440        1      386    None     423      38   \n",
      "480236  9ldb     A     P00339        2      332       1     331       2   \n",
      "480237  9ldb     B     P00339        2      332       1     331       2   \n",
      "480238  9ldt     A     P00339        2      332       1     331       2   \n",
      "480239  9ldt     B     P00339        2      332       1     331       2   \n",
      "480240  9lpr     A     P00778        1      198     15A     244     200   \n",
      "480241  9lyz     A     P00698        1      129       1     129      19   \n",
      "480242  9mht     A     P05102        1      327       1     327       1   \n",
      "480243  9msi     A     P19614        2       66       1      65       1   \n",
      "480244  9nse     A     P29473        1      444    None     482      39   \n",
      "480245  9nse     B     P29473        1      444    None     482      39   \n",
      "480246  9pai     A     P05121        1      346      19     364      24   \n",
      "480247  9pai     B     P05121        1       33     365     397     370   \n",
      "480248  9pap     A     P00784        1      212       1     212     134   \n",
      "480249  9pcy     A     P00287        1       99       1      99       1   \n",
      "480250  9pti     A     P00974        1       58       1      58      36   \n",
      "480251  9rat     A     P61823        1      124       1     124      27   \n",
      "480252  9rnt     A     P00651        1      104       1     104      27   \n",
      "480253  9rsa     A     P61823        1      124       1     124      27   \n",
      "480254  9rsa     B     P61823        1      124       1     124      27   \n",
      "480255  9rub     A     P04718        1      466    None    None       1   \n",
      "480256  9rub     B     P04718        1      466    None    None       1   \n",
      "480257  9wga     A     P02876        1      171       1     171      28   \n",
      "480258  9wga     B     P02876        1      171       1     171      28   \n",
      "480259  9xia     A     P24300        1      388       1    None       1   \n",
      "480260  9xim     A     P12851        1      393    None     394       2   \n",
      "480261  9xim     B     P12851        1      393    None     394       2   \n",
      "480262  9xim     C     P12851        1      393    None     394       2   \n",
      "480263  9xim     D     P12851        1      393    None     394       2   \n",
      "\n",
      "        SP_END           0       1  \n",
      "0          154      Q0KIY9  P02185  \n",
      "1           40      Q76YA6  P00720  \n",
      "2          164      Q76YA6  P00720  \n",
      "3          154      Q0KIY9  P02185  \n",
      "4           40      Q76YA6  P00720  \n",
      "5          164      Q76YA6  P00720  \n",
      "6          154      Q0KIY9  P02185  \n",
      "7           44      Q76YA6  P00720  \n",
      "8          164      Q76YA6  P00720  \n",
      "9           44      Q76YA6  P00720  \n",
      "10         164      Q76YA6  P00720  \n",
      "11         154      Q0KIY9  P02185  \n",
      "12         154      Q0KIY9  P02185  \n",
      "13         154      Q0KIY9  P02185  \n",
      "14         164      Q76YA6  P00720  \n",
      "15         154      Q0KIY9  P02185  \n",
      "16         164      Q76YA6  P00720  \n",
      "17         154      Q0KIY9  P02185  \n",
      "18         164      Q76YA6  P00720  \n",
      "19         154      Q0KIY9  P02185  \n",
      "20         210  A0A0D9R8K4  P09211  \n",
      "21         210  A0A0D9R8K4  P09211  \n",
      "22         327  A0A1F3C0H1  P05102  \n",
      "23         164      Q76YA6  P00720  \n",
      "24         154      Q0KIY9  P02185  \n",
      "25         164      Q76YA6  P00720  \n",
      "26         154      Q0KIY9  P02185  \n",
      "27         164      Q76YA6  P00720  \n",
      "28         154      Q0KIY9  P02185  \n",
      "29         164      Q76YA6  P00720  \n",
      "...        ...         ...     ...  \n",
      "480234      54  A0A1S3RMY0  P01315  \n",
      "480235     423  A0A2G9SGU6  P50440  \n",
      "480236     332  A0A286ZXT7  P00339  \n",
      "480237     332  A0A286ZXT7  P00339  \n",
      "480238     332  A0A286ZXT7  P00339  \n",
      "480239     332  A0A286ZXT7  P00339  \n",
      "480240     397  A0A108U4M2  P00778  \n",
      "480241     147  A0A1U8D6P8  P00698  \n",
      "480242     327  A0A1F3C0H1  P05102  \n",
      "480243      65      J7I8W2  P19614  \n",
      "480244     482  A0A2I0U3N9  P29473  \n",
      "480245     482  A0A2I0U3N9  P29473  \n",
      "480246     369      L5K8V6  P05121  \n",
      "480247     402      L5K8V6  P05121  \n",
      "480248     345      M5VNV5  P00784  \n",
      "480249      99      C6SZV4  P00287  \n",
      "480250      93  A0A2Y9F6C1  P00974  \n",
      "480251     150      W0UVC3  P61823  \n",
      "480252     130      B2W6U3  P00651  \n",
      "480253     150      W0UVC3  P61823  \n",
      "480254     150      W0UVC3  P61823  \n",
      "480255     466  A0A2N2V470  P04718  \n",
      "480256     466  A0A2N2V470  P04718  \n",
      "480257     198  A0A1D5SBE4  P02876  \n",
      "480258     198  A0A1D5SBE4  P02876  \n",
      "480259     388      P22857  P24300  \n",
      "480260     394      P22857  P12851  \n",
      "480261     394      P22857  P12851  \n",
      "480262     394      P22857  P12851  \n",
      "480263     394      P22857  P12851  \n",
      "\n",
      "[480264 rows x 11 columns]\n"
     ]
    }
   ],
   "source": [
    "#pdb to uniprot map w uniclust cluster rep for each struct\n",
    "#grab aln for clust \n",
    "\n",
    "pdbuni = './pdb_chain_uniprot.csv'\n",
    "dfuni = pd.read_csv( pdbuni , low_memory = False , comment = '#') \n",
    "dfuni = dfuni.merge(dfclust , how= 'left' , right_on = 1 , left_on = 'SP_PRIMARY' )\n",
    "print(dfuni)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use column 0 to retreive aln for pdb\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           PDB CHAIN SP_PRIMARY                WITH_STRING EVIDENCE  \\\n",
      "0         101m     A       IPRO         InterPro:IPR000971      IEA   \n",
      "1         101m     A       IPRO         InterPro:IPR002335      IEA   \n",
      "2         101m     A       IPRO         InterPro:IPR002335      IEA   \n",
      "3         101m     A       IPRO         InterPro:IPR002335      IEA   \n",
      "4         101m     A       IPRO         InterPro:IPR012292      IEA   \n",
      "5         101m     A       IPRO         InterPro:IPR012292      IEA   \n",
      "6         101m     A     P02185       UniProtKB-KW:KW-0479      IEA   \n",
      "7         101m     A     P02185       UniProtKB-KW:KW-0561      IEA   \n",
      "8         101m     A     P02185       UniProtKB-KW:KW-0561      IEA   \n",
      "9         102l     A       IPRO         InterPro:IPR001165      IEA   \n",
      "10        102l     A       IPRO         InterPro:IPR001165      IEA   \n",
      "11        102l     A       IPRO         InterPro:IPR002196      IEA   \n",
      "12        102l     A       IPRO         InterPro:IPR002196      IEA   \n",
      "13        102l     A       IPRO         InterPro:IPR002196      IEA   \n",
      "14        102l     A       IPRO         InterPro:IPR034690      IEA   \n",
      "15        102l     A       IPRO         InterPro:IPR034690      IEA   \n",
      "16        102l     A       IPRO         InterPro:IPR034690      IEA   \n",
      "17        102l     A       IPRO         InterPro:IPR034690      IEA   \n",
      "18        102m     A       IPRO         InterPro:IPR000971      IEA   \n",
      "19        102m     A       IPRO         InterPro:IPR002335      IEA   \n",
      "20        102m     A       IPRO         InterPro:IPR002335      IEA   \n",
      "21        102m     A       IPRO         InterPro:IPR002335      IEA   \n",
      "22        102m     A       IPRO         InterPro:IPR012292      IEA   \n",
      "23        102m     A       IPRO         InterPro:IPR012292      IEA   \n",
      "24        102m     A     P02185       UniProtKB-KW:KW-0479      IEA   \n",
      "25        102m     A     P02185       UniProtKB-KW:KW-0561      IEA   \n",
      "26        102m     A     P02185       UniProtKB-KW:KW-0561      IEA   \n",
      "27        103l     A       IPRO         InterPro:IPR001165      IEA   \n",
      "28        103l     A       IPRO         InterPro:IPR001165      IEA   \n",
      "29        103l     A       IPRO         InterPro:IPR002196      IEA   \n",
      "...        ...   ...        ...                        ...      ...   \n",
      "28817029  9xim     C       IPRO         InterPro:IPR001998      IEA   \n",
      "28817030  9xim     C       IPRO         InterPro:IPR001998      IEA   \n",
      "28817031  9xim     C       IPRO         InterPro:IPR013453      IEA   \n",
      "28817032  9xim     C       IPRO         InterPro:IPR013453      IEA   \n",
      "28817033  9xim     C     P12851                 EC:5.3.1.5      IEA   \n",
      "28817034  9xim     C     P12851       UniProtKB-KW:KW-0119      IEA   \n",
      "28817035  9xim     C     P12851       UniProtKB-KW:KW-0413      IEA   \n",
      "28817036  9xim     C     P12851       UniProtKB-KW:KW-0479      IEA   \n",
      "28817037  9xim     C     P12851       UniProtKB-KW:KW-0859      IEA   \n",
      "28817038  9xim     C     P12851       UniProtKB-KW:KW-0963      IEA   \n",
      "28817039  9xim     C     P12851  UniProtKB-SubCell:SL-0086      IEA   \n",
      "28817040  9xim     C     P12851        UniRule:UR000089075      IEA   \n",
      "28817041  9xim     C     P12851        UniRule:UR000089075      IEA   \n",
      "28817042  9xim     C     P12851        UniRule:UR000089075      IEA   \n",
      "28817043  9xim     C     P12851        UniRule:UR000089075      IEA   \n",
      "28817044  9xim     D       IPRO         InterPro:IPR001998      IEA   \n",
      "28817045  9xim     D       IPRO         InterPro:IPR001998      IEA   \n",
      "28817046  9xim     D       IPRO         InterPro:IPR013453      IEA   \n",
      "28817047  9xim     D       IPRO         InterPro:IPR013453      IEA   \n",
      "28817048  9xim     D     P12851                 EC:5.3.1.5      IEA   \n",
      "28817049  9xim     D     P12851       UniProtKB-KW:KW-0119      IEA   \n",
      "28817050  9xim     D     P12851       UniProtKB-KW:KW-0413      IEA   \n",
      "28817051  9xim     D     P12851       UniProtKB-KW:KW-0479      IEA   \n",
      "28817052  9xim     D     P12851       UniProtKB-KW:KW-0859      IEA   \n",
      "28817053  9xim     D     P12851       UniProtKB-KW:KW-0963      IEA   \n",
      "28817054  9xim     D     P12851  UniProtKB-SubCell:SL-0086      IEA   \n",
      "28817055  9xim     D     P12851        UniRule:UR000089075      IEA   \n",
      "28817056  9xim     D     P12851        UniRule:UR000089075      IEA   \n",
      "28817057  9xim     D     P12851        UniRule:UR000089075      IEA   \n",
      "28817058  9xim     D     P12851        UniRule:UR000089075      IEA   \n",
      "\n",
      "               GO_ID  \n",
      "0         GO:0020037  \n",
      "1         GO:0015671  \n",
      "2         GO:0019825  \n",
      "3         GO:0020037  \n",
      "4         GO:0019825  \n",
      "5         GO:0020037  \n",
      "6         GO:0046872  \n",
      "7         GO:0005344  \n",
      "8         GO:0015671  \n",
      "9         GO:0003796  \n",
      "10        GO:0016998  \n",
      "11        GO:0003796  \n",
      "12        GO:0009253  \n",
      "13        GO:0016998  \n",
      "14        GO:0003796  \n",
      "15        GO:0009253  \n",
      "16        GO:0019076  \n",
      "17        GO:0019835  \n",
      "18        GO:0020037  \n",
      "19        GO:0015671  \n",
      "20        GO:0019825  \n",
      "21        GO:0020037  \n",
      "22        GO:0019825  \n",
      "23        GO:0020037  \n",
      "24        GO:0046872  \n",
      "25        GO:0005344  \n",
      "26        GO:0015671  \n",
      "27        GO:0003796  \n",
      "28        GO:0016998  \n",
      "29        GO:0003796  \n",
      "...              ...  \n",
      "28817029  GO:0005975  \n",
      "28817030  GO:0009045  \n",
      "28817031  GO:0009045  \n",
      "28817032  GO:0042732  \n",
      "28817033  GO:0009045  \n",
      "28817034  GO:0005975  \n",
      "28817035  GO:0016853  \n",
      "28817036  GO:0046872  \n",
      "28817037  GO:0042732  \n",
      "28817038  GO:0005737  \n",
      "28817039  GO:0005737  \n",
      "28817040  GO:0000287  \n",
      "28817041  GO:0005737  \n",
      "28817042  GO:0009045  \n",
      "28817043  GO:0042732  \n",
      "28817044  GO:0005975  \n",
      "28817045  GO:0009045  \n",
      "28817046  GO:0009045  \n",
      "28817047  GO:0042732  \n",
      "28817048  GO:0009045  \n",
      "28817049  GO:0005975  \n",
      "28817050  GO:0016853  \n",
      "28817051  GO:0046872  \n",
      "28817052  GO:0042732  \n",
      "28817053  GO:0005737  \n",
      "28817054  GO:0005737  \n",
      "28817055  GO:0000287  \n",
      "28817056  GO:0005737  \n",
      "28817057  GO:0009045  \n",
      "28817058  GO:0042732  \n",
      "\n",
      "[28817059 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "#merge with GO terms\n",
    "pdbgo = './pdb_chain_go.csv'\n",
    "dfgo = pd.read_csv( pdbgo , error_bad_lines=False , warn_bad_lines= False ,comment = '#')\n",
    "print(dfgo)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = tf.ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction= 0.90\n",
    "K.set_session(tf.Session(config=config))\n",
    "\n",
    "#systematicall probe net arch\n",
    "#insert bottleneck in dense\n",
    "\n",
    "#first part of the network, stacked GRU\n",
    "LSTMoutdim_max = 500\n",
    "LSTMoutdim_min = 500\n",
    "\n",
    "LSTMlayers = 2\n",
    "\n",
    "Densegrulayers = 2\n",
    "Densegruoutdim_min = 300\n",
    "Densegruoutdim_max = 300\n",
    "\n",
    "retrain = False\n",
    "print(XTRAINrows.shape)\n",
    "print(XVALIDrows.shape)\n",
    "\n",
    "def bottleneck( minn, maxn, layers ):\n",
    "    split = int(layers/2)\n",
    "    slope = (minn - maxn) / split\n",
    "    units =[maxn]    \n",
    "    last = maxn\n",
    "    for k in range(split):\n",
    "        last += slope \n",
    "        units.append(int(last))\n",
    "    slope = -slope\n",
    "    for k in range(split):\n",
    "        last += slope \n",
    "        units.append(int(last))\n",
    "    return units\n",
    "\n",
    "lstmbottle = bottleneck(LSTMoutdim_min , LSTMoutdim_max  , LSTMlayers )\n",
    "bottle = bottleneck(Densegruoutdim_min , Densegruoutdim_max  ,Densegrulayers )\n",
    "print(lstmbottle)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retrain = True\n",
    "if retrain == False:\n",
    "    inputrnn = Input(name='Seqin', shape=( XTRAINrows.shape[1] ,XTRAINrows.shape[2] ) )\n",
    "    layer = BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001, center=True, scale=True, beta_initializer='zeros', gamma_initializer='ones')\n",
    "    x = layer(inputrnn)\n",
    "    print(x)\n",
    "    \n",
    "    \n",
    "    for b in lstmbottle:\n",
    "            #layer = CuDNNGRU(LSTMoutdim ,  name='gru_'+str(n),\n",
    "            #return_sequences=True, return_state=False, go_backwards=False, stateful=False )\n",
    "            \n",
    "            layer = CuDNNLSTM(b , kernel_initializer='glorot_uniform', recurrent_initializer='orthogonal',\n",
    "                    bias_initializer='zeros', unit_forget_bias=True, kernel_regularizer=None, \n",
    "                    recurrent_regularizer=None, bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, \n",
    "                    recurrent_constraint=None, bias_constraint=None, return_sequences=True, return_state=False, stateful=False)\n",
    "            \n",
    "            layer = Bidirectional(layer, merge_mode='concat', weights=None)\n",
    "            x = layer(x)\n",
    "            \n",
    "            layer = Dropout(.5 , noise_shape=None, seed=None)\n",
    "            x = layer(x)\n",
    "            \n",
    "            layer = BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001, center=True, scale=True, beta_initializer='zeros', gamma_initializer='ones')\n",
    "            x = layer(x)\n",
    "\n",
    "    #layer = CuDNNGRU(LSTMoutdim ,  name='gru_'+str(n+1),\n",
    "    #return_sequences=True, return_state=False, go_backwards=False, stateful=False )\n",
    "    \n",
    "    #todo... regularizers \n",
    "    layer = CuDNNLSTM( LSTMoutdim_max , kernel_initializer='glorot_uniform', recurrent_initializer='orthogonal', \n",
    "                              bias_initializer='zeros', unit_forget_bias=True, kernel_regularizer=None, \n",
    "                              recurrent_regularizer=None, bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, \n",
    "                              recurrent_constraint=None, bias_constraint=None, return_sequences=True, return_state=False, stateful=False)\n",
    "    x = layer(x)\n",
    "    layer = BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001, center=True, scale=True, beta_initializer='zeros', gamma_initializer='ones')\n",
    "    x = layer(x)\n",
    "\n",
    "    x =  Flatten()(x)\n",
    "    layer = Dropout(.5 , noise_shape=None, seed=None)\n",
    "    x = layer(x)\n",
    "    \n",
    "    layer = Dense( YTRAINpca.shape[1] , activation='linear'  )\n",
    "    x = layer(x)\n",
    "    \n",
    "    \n",
    "    layer = Dense( YTRAINpca.shape[1] , activation='linear'  )\n",
    "    xpre= layer(x)\n",
    "    \n",
    "    \n",
    "    #final transform to img\n",
    "    layer = Dense( YTRAIN.shape[2] * YTRAIN.shape[1] , activation='linear'  )\n",
    "    x = layer(xpre)\n",
    "    \n",
    "    layer = BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001, center=True, scale=True, beta_initializer='zeros', gamma_initializer='ones')\n",
    "    x = layer(x)\n",
    "    \n",
    "    layer = Reshape( ( YTRAIN.shape[1], YTRAIN.shape[2] ))\n",
    "    xfinal = layer(x)\n",
    "    \n",
    "    \n",
    "    with tf.device('/cpu:0'):\n",
    "        model = Model(inputs = [inputrnn] , outputs = [xpre,xfinal] )\n",
    "    o = keras.optimizers.Adadelta(lr=.0001, rho=0.95)\n",
    "    model.compile( optimizer=o, loss= 'mean_absolute_percentage_error' , metrics=['mae'] )\n",
    "else:\n",
    "    model = print('Load the model..')\n",
    "    modelfile = 'model-12_01_2019_12_12_34_169126.h5'\n",
    "    model = load_model(modelfile, custom_objects= { 'tf' : tf  } )\n",
    "    o = keras.optimizers.Adadelta(lr=.025, rho=0.95)\n",
    "    model.compile( optimizer=o, loss= 'mean_absolute_error' , metrics=['mae'])\n",
    "\n",
    "max_len = 3000\n",
    "mc = ModelCheckpoint(modelfile, monitor = 'val_loss', mode = 'min', verbose = 1, save_best_only = True)\n",
    "es = EarlyStopping(monitor = 'val_loss', mode = 'min', verbose = 2, patience = es_patience)\n",
    "history = model.fit( { 'Seqin': XTRAINrows } , [YTRAINpca,YTRAIN] , batch_size = None , verbose = 2 , epochs = 100000 ,  validation_data=([XVALIDrows], [YVALIDpca,YVALID] ), callbacks=[es, mc])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
