{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa21c5b5-c936-4e27-96d8-4c076d25a6d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install tf2_gnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "38345411-76ce-41db-a061-9783f13d8a91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "from typing import Any, Dict, Iterable, List, Iterator, Tuple, Optional, Set\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from dpu_utils.utils import RichPath\n",
    "\n",
    "from tf2_gnn.data.graph_dataset import DataFold, GraphSample, GraphBatchTFDataDescription, GraphDataset\n",
    "from tf2_gnn.data.utils import compute_number_of_edge_types, get_tied_edge_types, process_adjacency_lists\n",
    "\n",
    "\n",
    "class PPIGraphSample(GraphSample):\n",
    "    \"\"\"Data structure holding a single PPI graph.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        adjacency_lists: List[np.ndarray],\n",
    "        type_to_node_to_num_inedges: np.ndarray,\n",
    "        node_features: np.ndarray,\n",
    "        node_labels: np.ndarray,\n",
    "    ):\n",
    "        super().__init__(adjacency_lists, type_to_node_to_num_inedges, node_features)\n",
    "        self._node_labels = node_labels\n",
    "\n",
    "    @property\n",
    "    def node_labels(self) -> np.ndarray:\n",
    "        \"\"\"Node labels to predict as ndarray of shape [V, C]\"\"\"\n",
    "        return self._node_labels\n",
    "\n",
    "\n",
    "class PPIDataset(GraphDataset[PPIGraphSample]):\n",
    "    @classmethod\n",
    "    def get_default_hyperparameters(cls) -> Dict[str, Any]:\n",
    "        super_hypers = super().get_default_hyperparameters()\n",
    "        this_hypers = {\n",
    "            \"max_nodes_per_batch\": 10000,\n",
    "            \"add_self_loop_edges\": True,\n",
    "            \"tie_fwd_bkwd_edges\": False,\n",
    "        }\n",
    "        super_hypers.update(this_hypers)\n",
    "\n",
    "        return super_hypers\n",
    "\n",
    "    @staticmethod\n",
    "    def default_data_path() -> str:\n",
    "        return \"data/ppi\"\n",
    "\n",
    "    def __init__(self, params: Dict[str, Any], metadata: Optional[Dict[str, Any]] = None, **kwargs):\n",
    "        super().__init__(params, metadata=metadata, **kwargs)\n",
    "\n",
    "        self._tied_fwd_bkwd_edge_types = get_tied_edge_types(\n",
    "            tie_fwd_bkwd_edges=params[\"tie_fwd_bkwd_edges\"], num_fwd_edge_types=1,\n",
    "        )\n",
    "\n",
    "        self._num_edge_types = compute_number_of_edge_types(\n",
    "            tied_fwd_bkwd_edge_types=self._tied_fwd_bkwd_edge_types,\n",
    "            num_fwd_edge_types=1,\n",
    "            add_self_loop_edges=params[\"add_self_loop_edges\"],\n",
    "        )\n",
    "\n",
    "        # Things that will be filled once we load data:\n",
    "        self._loaded_data: Dict[DataFold, List[PPIGraphSample]] = {}\n",
    "\n",
    "    @property\n",
    "    def num_edge_types(self) -> int:\n",
    "        return self._num_edge_types\n",
    "\n",
    "    @property\n",
    "    def node_feature_shape(self) -> Tuple:\n",
    "        some_data_fold = next(iter(self._loaded_data.values()))\n",
    "        return (some_data_fold[0].node_features.shape[-1],)\n",
    "\n",
    "    @property\n",
    "    def num_node_target_labels(self) -> int:\n",
    "        return 121\n",
    "\n",
    "    # -------------------- Data Loading --------------------\n",
    "    def load_data(self, path: RichPath, folds_to_load: Optional[Set[DataFold]] = None) -> None:\n",
    "        # Data in format as downloaded from https://s3.us-east-2.amazonaws.com/dgl.ai/dataset/ppi.zip\n",
    "        # If we haven't defined what folds to load, load all:\n",
    "        if folds_to_load is None:\n",
    "            folds_to_load = {DataFold.TRAIN, DataFold.VALIDATION, DataFold.TEST}\n",
    "\n",
    "        if DataFold.TRAIN in folds_to_load:\n",
    "            self._loaded_data[DataFold.TRAIN] = self.__load_data(path, DataFold.TRAIN)\n",
    "        if DataFold.VALIDATION in folds_to_load:\n",
    "            self._loaded_data[DataFold.VALIDATION] = self.__load_data(path, DataFold.VALIDATION)\n",
    "        if DataFold.TEST in folds_to_load:\n",
    "            self._loaded_data[DataFold.TEST] = self.__load_data(path, DataFold.TEST)\n",
    "\n",
    "    def load_data_from_list(\n",
    "        self, datapoints: List[Dict[str, Any]], target_fold: DataFold = DataFold.TEST\n",
    "    ):\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def __load_data(self, data_dir: RichPath, data_fold: DataFold) -> List[PPIGraphSample]:\n",
    "        if data_fold == DataFold.TRAIN:\n",
    "            data_name = \"train\"\n",
    "        elif data_fold == DataFold.VALIDATION:\n",
    "            data_name = \"valid\"\n",
    "        elif data_fold == DataFold.TEST:\n",
    "            data_name = \"test\"\n",
    "        else:\n",
    "            raise ValueError(\"Unknown data fold '%s'\" % str(data_fold))\n",
    "        print(\" Loading PPI %s data from %s.\" % (data_name, data_dir))\n",
    "\n",
    "        graph_json_data = data_dir.join(\"%s_graph.json\" % data_name).read_by_file_suffix()\n",
    "        node_to_features = data_dir.join(\"%s_feats.npy\" % data_name).read_by_file_suffix()\n",
    "        node_to_labels = data_dir.join(\"%s_labels.npy\" % data_name).read_by_file_suffix()\n",
    "        node_to_graph_id = data_dir.join(\"%s_graph_id.npy\" % data_name).read_by_file_suffix()\n",
    "\n",
    "        # We read in all the data in two steps:\n",
    "        #  (1) Read features and labels. Implicitly, this gives us the number of nodes per graph.\n",
    "        #  (2) Read all edges, and shift them so that each graph starts with node 0.\n",
    "\n",
    "        graph_id_to_edges: Dict[int, List[Tuple[int, int]]] = {}\n",
    "        graph_id_to_features: Dict[int, List[np.ndarray]] = {}\n",
    "        graph_id_to_labels: Dict[int, List[np.ndarray]] = {}\n",
    "        graph_id_to_node_offset: Dict[int, int] = {}\n",
    "\n",
    "        num_total_nodes = node_to_features.shape[0]\n",
    "        for node_id in range(num_total_nodes):\n",
    "            graph_id = node_to_graph_id[node_id]\n",
    "\n",
    "            # In case we are entering a new graph, note its ID, so that we can normalise everything to start at 0\n",
    "            if graph_id not in graph_id_to_edges:\n",
    "                graph_id_to_edges[graph_id] = []\n",
    "                graph_id_to_features[graph_id] = []\n",
    "                graph_id_to_labels[graph_id] = []\n",
    "                graph_id_to_node_offset[graph_id] = node_id\n",
    "\n",
    "            graph_id_to_features[graph_id].append(node_to_features[node_id])\n",
    "            graph_id_to_labels[graph_id].append(node_to_labels[node_id])\n",
    "\n",
    "        for edge_info in graph_json_data[\"links\"]:\n",
    "            src_node, tgt_node = edge_info[\"source\"], edge_info[\"target\"]\n",
    "            # First, shift node IDs so that each graph starts at node 0:\n",
    "            graph_id = node_to_graph_id[src_node]\n",
    "            graph_node_offset = graph_id_to_node_offset[graph_id]\n",
    "            src_node, tgt_node = src_node - graph_node_offset, tgt_node - graph_node_offset\n",
    "\n",
    "            graph_id_to_edges[graph_id].append((src_node, tgt_node))\n",
    "\n",
    "        final_graphs = []\n",
    "        for graph_id in graph_id_to_edges.keys():\n",
    "            num_nodes = len(graph_id_to_features[graph_id])\n",
    "\n",
    "            adjacency_lists, type_to_node_to_num_inedges = process_adjacency_lists(\n",
    "                adjacency_lists=[graph_id_to_edges[graph_id]],\n",
    "                num_nodes=num_nodes,\n",
    "                add_self_loop_edges=self.params[\"add_self_loop_edges\"],\n",
    "                tied_fwd_bkwd_edge_types=self._tied_fwd_bkwd_edge_types,\n",
    "            )\n",
    "\n",
    "            final_graphs.append(\n",
    "                PPIGraphSample(\n",
    "                    adjacency_lists=adjacency_lists,\n",
    "                    type_to_node_to_num_inedges=type_to_node_to_num_inedges,\n",
    "                    node_features=np.array(graph_id_to_features[graph_id]),\n",
    "                    node_labels=np.array(graph_id_to_labels[graph_id]),\n",
    "                )\n",
    "            )\n",
    "\n",
    "        return final_graphs\n",
    "\n",
    "    # -------------------- Minibatching --------------------\n",
    "    def get_batch_tf_data_description(self) -> GraphBatchTFDataDescription:\n",
    "        data_description = super().get_batch_tf_data_description()\n",
    "        return GraphBatchTFDataDescription(\n",
    "            batch_features_types=data_description.batch_features_types,\n",
    "            batch_features_shapes=data_description.batch_features_shapes,\n",
    "            batch_labels_types={**data_description.batch_labels_types, \"node_labels\": tf.float32},\n",
    "            batch_labels_shapes={**data_description.batch_labels_shapes, \"node_labels\": (None, None)},\n",
    "        )\n",
    "\n",
    "    def _graph_iterator(self, data_fold: DataFold) -> Iterator[PPIGraphSample]:\n",
    "        loaded_data = self._loaded_data[data_fold]\n",
    "        if data_fold == DataFold.TRAIN:\n",
    "            np.random.shuffle(loaded_data)\n",
    "        return iter(loaded_data)\n",
    "\n",
    "    def _new_batch(self) -> Dict[str, Any]:\n",
    "        new_batch = super()._new_batch()\n",
    "        new_batch[\"node_labels\"] = []\n",
    "        return new_batch\n",
    "\n",
    "    def _add_graph_to_batch(self, raw_batch, graph_sample: PPIGraphSample) -> None:\n",
    "        super()._add_graph_to_batch(raw_batch, graph_sample)\n",
    "        raw_batch[\"node_labels\"].append(graph_sample.node_labels)\n",
    "\n",
    "    def _finalise_batch(self, raw_batch) -> Tuple[Dict[str, Any], Dict[str, Any]]:\n",
    "        batch_features, batch_labels = super()._finalise_batch(raw_batch)\n",
    "        batch_labels[\"node_labels\"] = np.concatenate(raw_batch[\"node_labels\"], axis=0)\n",
    "        return batch_features, batch_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c09838-cc17-426e-9d75-19fdb9cac4cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
